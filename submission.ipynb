{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b544ff9a-e5c4-4121-828d-295bb74bc838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================\n",
    "# INSTALL AND LOAD LIBRARIES\n",
    "# ==================\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn\n",
    "!pip install xgboost\n",
    "!pip install joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import math\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8b0ae5-c823-4cb7-9d10-039b0bb890af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the scr folder to the Python path\n",
    "sys.path.append('./src')\n",
    "\n",
    "# Load custom library (soccer_dynamics_1.py)\n",
    "from soccer_dynamics_1 import load_match_data, calculate_metrics, train_xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cc5b5b-167d-439e-aa3d-76a18d738db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate start and end frame metrics using tracking data\n",
    "\n",
    "# Match IDs\n",
    "match_ids = [1886347, 1899585, 1925299, 1953632, 1996435, 2006229, 2011166, 2013725, 2015213, 2017461]\n",
    "\n",
    "# Common inputs\n",
    "Lf_OBR = 0.2\n",
    "Lf_PO = 0.8\n",
    "Lf_OBE = 0.1\n",
    "\n",
    "# Lists to collect all M_start and M_end DataFrames across matches\n",
    "all_M_start_list = []\n",
    "all_M_end_list = []\n",
    "\n",
    "# Loop through each match_id\n",
    "for match_id in match_ids:\n",
    "    # Load and process event and tracking data for current match\n",
    "    po_obr, tracking = load_match_data(match_id)\n",
    "    \n",
    "    # Process frame_start\n",
    "    frame_type = 'frame_start'\n",
    "    M_list = []\n",
    "    for value in po_obr[frame_type]:\n",
    "        M = calculate_metrics(frame_type, value, Lf_OBR, Lf_PO, Lf_OBE, po_obr, tracking, match_id)\n",
    "        M_list.append(M)\n",
    "    M_start = pd.concat(M_list, ignore_index=True)\n",
    "    M_start['match_id'] = match_id  # Add match identifier\n",
    "    all_M_start_list.append(M_start)\n",
    "    \n",
    "    # Process frame_end\n",
    "    frame_type = 'frame_end'\n",
    "    M_list = []\n",
    "    for value in po_obr[frame_type]:\n",
    "        M = calculate_metrics(frame_type, value, Lf_OBR, Lf_PO, Lf_OBE, po_obr, tracking, match_id)\n",
    "        M_list.append(M)\n",
    "    M_end = pd.concat(M_list, ignore_index=True)\n",
    "    M_end['match_id'] = match_id  # Add match identifier\n",
    "    all_M_end_list.append(M_end)\n",
    "\n",
    "# Combine ALL M_start DataFrames together (across all matches)\n",
    "all_M_start = pd.concat(all_M_start_list, ignore_index=True)\n",
    "\n",
    "# Combine ALL M_end DataFrames together (across all matches)  \n",
    "all_M_end = pd.concat(all_M_end_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10639c69-e2ca-41c4-b62b-87a1a2f8c28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_M_start.to_excel('all_M_start.xlsx', index=False)\n",
    "all_M_end.to_excel('all_M_end.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6891d381-d066-4cdb-ac20-8636101234fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_M_start = pd.read_excel('all_M_start.xlsx')\n",
    "all_M_end = pd.read_excel('all_M_end.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed6d123-f4bd-411c-bc21-79100247ff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only xthreat > 0\n",
    "all_M_start = all_M_start[all_M_start['xthreat'] > 0]\n",
    "all_M_end = all_M_end[all_M_end['xthreat'] > 0]\n",
    "\n",
    "# Combine start and end dataframes\n",
    "M = pd.concat([all_M_start, all_M_end], ignore_index=True)\n",
    "# M.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7fd00d-3372-4b6d-986f-b56e8cab98de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data for regression model\n",
    "\n",
    "# Select test match_id\n",
    "match_id_test = 2017461\n",
    "    # [1886347, 1899585, 1925299, 1953632, 1996435, 2006229, 2011166, 2013725, 2015213, 2017461]\n",
    "\n",
    "# Remove test match_id from master dataset\n",
    "M_train = M[M['match_id'] != match_id_test]\n",
    "\n",
    "# Create X and Y for regression\n",
    "X = M_train.iloc[:, 1:-1].values\n",
    "Y = M_train.iloc[:, :1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687231c4-b0f4-4e8e-9b10-2d4e251e79d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost regression on training data\n",
    "results = train_xgb_model(X, Y, M_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Unpack parameters\n",
    "(best_xgb_model, y_val, y_pred_best, importance_df, \n",
    " r2_best, mae_best, rmse_best) = (\n",
    "    results['best_model'],\n",
    "    results['predictions']['y_val'], \n",
    "    results['predictions']['y_pred'],\n",
    "    results['importance_df'],\n",
    "    results['metrics']['R2'],\n",
    "    results['metrics']['MAE'], \n",
    "    results['metrics']['RMSE']\n",
    ")\n",
    "\n",
    "# -----------------------------------\n",
    "# VISUALIZATIONS WITH METRICS\n",
    "# -----------------------------------\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Collect metrics for display\n",
    "text_metrics = (\n",
    "    f\"R² = {r2_best:.3f}\\n\"\n",
    "    f\"MAE = {mae_best:.3f}\\n\"\n",
    "    f\"RMSE = {rmse_best:.3f}\\n\"\n",
    ")\n",
    "\n",
    "# 1. Actual vs Predicted\n",
    "axes[0, 0].scatter(y_val, y_pred_best, alpha=0.5, s=20)\n",
    "axes[0, 0].plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
    "axes[0, 0].set_xlabel('Actual xThreat')\n",
    "axes[0, 0].set_ylabel('Predicted xThreat')\n",
    "axes[0, 0].set_title('XGBoost: Actual vs Predicted - Training')\n",
    "axes[0, 0].text(\n",
    "    0.05, 0.95, text_metrics,\n",
    "    transform=axes[0, 0].transAxes,\n",
    "    fontsize=10, verticalalignment='top',\n",
    "    bbox=dict(facecolor='white', alpha=0.7, edgecolor='none')\n",
    ")\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Residual Plot\n",
    "residuals = y_val - y_pred_best\n",
    "axes[0, 1].scatter(y_pred_best, residuals, alpha=0.5, s=20)\n",
    "axes[0, 1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[0, 1].set_xlabel('Predicted xThreat')\n",
    "axes[0, 1].set_ylabel('Residuals')\n",
    "axes[0, 1].set_title('Residual Plot - Training')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add residual std info\n",
    "res_std = np.std(residuals)\n",
    "axes[0, 1].text(\n",
    "    0.05, 0.95, f\"\",\n",
    "    transform=axes[0, 1].transAxes,\n",
    "    fontsize=10, verticalalignment='top',\n",
    "    bbox=dict(facecolor='white', alpha=0.7, edgecolor='none')\n",
    ")\n",
    "\n",
    "# 3. Feature Importance Plot\n",
    "top_n = min(20, len(importance_df))\n",
    "top_features = importance_df.head(top_n)\n",
    "axes[1, 0].barh(range(top_n), top_features['importance'], color='steelblue')\n",
    "axes[1, 0].set_yticks(range(top_n))\n",
    "axes[1, 0].set_yticklabels(top_features['feature'])\n",
    "axes[1, 0].set_xlabel('Importance Score')\n",
    "axes[1, 0].set_title(f'Top {top_n} Feature Importances - Training')\n",
    "axes[1, 0].invert_yaxis()\n",
    "\n",
    "# Feature importance stats\n",
    "avg_imp = importance_df['importance'].mean()\n",
    "max_imp = importance_df['importance'].max()\n",
    "axes[1, 0].text(\n",
    "    0.05, 0.95, f\"Avg Importance = {avg_imp:.3f}\\nMax = {max_imp:.3f}\",\n",
    "    transform=axes[1, 0].transAxes,\n",
    "    fontsize=10, verticalalignment='top',\n",
    "    bbox=dict(facecolor='white', alpha=0.6, edgecolor='none')\n",
    ")\n",
    "\n",
    "# 4. Distribution Comparison\n",
    "axes[1, 1].hist(y_val, alpha=0.5, bins=30, label='Actual', density=True)\n",
    "axes[1, 1].hist(y_pred_best, alpha=0.5, bins=30, label='Predicted', density=True)\n",
    "axes[1, 1].set_xlabel('xThreat Value')\n",
    "axes[1, 1].set_ylabel('Density')\n",
    "axes[1, 1].set_title('Distribution: Actual vs Predicted - Training')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the best model\n",
    "import joblib\n",
    "joblib.dump(best_xgb_model, 'xgb_xthreat_best_model.pkl')\n",
    "\n",
    "# Save feature importance\n",
    "importance_df.to_csv('feature_importance.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5c7bd2-2c99-4634-978e-68b0a70e5962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost regression on test data\n",
    "\n",
    "# Load trained model\n",
    "model = joblib.load('xgb_xthreat_best_model.pkl')\n",
    "\n",
    "# Load match data and create X and Y\n",
    "M_test = M[M['match_id'] == match_id_test]\n",
    "X = M_test.iloc[:, 1:-1].values\n",
    "Y = M_test.iloc[:, :1].values\n",
    "\n",
    "# Predict\n",
    "preds = model.predict(X)\n",
    "\n",
    "# Save\n",
    "results = pd.DataFrame({\n",
    "    'actual': Y.flatten(),\n",
    "    'predicted': preds\n",
    "})\n",
    "results.to_csv('match_predictions.csv', index=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Calculate metrics\n",
    "r2 = r2_score(Y, preds)\n",
    "mae = mean_absolute_error(Y, preds)\n",
    "rmse = np.sqrt(mean_squared_error(Y, preds))\n",
    "\n",
    "# Subplot 1: Actual vs Predicted with metrics\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(Y, preds, alpha=0.5)\n",
    "plt.plot([Y.min(), Y.max()], [Y.min(), Y.max()], 'r--')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title(f'Match {match_id_test}')\n",
    "\n",
    "# Add metrics text to scatter plot\n",
    "metrics_text = f'R² = {r2:.3f}\\nMAE = {mae:.3f}\\nRMSE = {rmse:.3f}'\n",
    "plt.text(0.05, 0.95, metrics_text, transform=plt.gca().transAxes,\n",
    "         fontsize=10, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Subplot 2: Residual plot (clean, no text)\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals = Y.flatten() - preds\n",
    "plt.scatter(preds, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Residual')\n",
    "plt.title('Residual Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('match_predictions.png', dpi=100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b7b2e7-c7f7-4368-a444-86d546520e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future analysis\n",
    "    # Find local min and max xthreat by varying L's to determine best and worst intercept point P for a Defender\n",
    "    # Freeze all metrics but vary da (OBR and PO) and vary db (OBE) to see the effect on xthreat by moving the play closer or further away from the goal  \n",
    "    # Separate models for OBR and PO. Currently combining both datasets.\n",
    "    # Inlcude OBR and PO events between Player Possesion start and end frames. Currently only considering events at the start and end frame.\n",
    "    # Separate models for each team. Alternate ML models.\n",
    "    # Deep dive into feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c066e-fd12-42a1-95dd-c03e84295e19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
